{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import math\n",
    "import statistics\n",
    "import tokenize\n",
    "import keyword\n",
    "from tempfile import NamedTemporaryFile\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./data/test_dataset_python.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(code_snippet):\n",
    "    \"\"\"\n",
    "    Extract lexical features from a given code snippet.\n",
    "    This function temporarily writes the code snippet to a file, then applies the lexical feature extractor functions.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    with NamedTemporaryFile(delete=False, mode='w', suffix='.py') as tmp:\n",
    "        tmp.write(code_snippet)\n",
    "        tmp_path = tmp.name\n",
    "\n",
    "    # Ensure the number of characters is calculated based on the code snippet directly\n",
    "    number_of_characters = len(code_snippet.replace('\\n', ''))\n",
    "\n",
    "    # Call feature extraction functions directly\n",
    "    features['log_of_numTokens'] = numTokens(tmp_path, number_of_characters)\n",
    "    features['avg_line_length'] = lineLength(tmp_path)\n",
    "    features['stdDev_line_length'] = stdevLineLength(tmp_path)\n",
    "    features['log_of_numComments'] = numComments(tmp_path, number_of_characters)\n",
    "    features['log_of_numFunctions'] = numFunctions(tmp_path, number_of_characters)\n",
    "    features['dict_log_of_numKeywords'] = numKeywords(tmp_path, number_of_characters)\n",
    "    features['dict_TF_wordUnigrams'] = tfwordUnigram(tmp_path)\n",
    "    features['average_params'] = avgParams(tmp_path)\n",
    "    features['stdDev_numParams'] = stdevNumParams(tmp_path)\n",
    "    features['log_of_python_keywords'] = pythonkeywords(tmp_path, number_of_characters)\n",
    "    features['log_of_numLiterals'] = numLiterals(tmp_path, number_of_characters)\n",
    "    \n",
    "    # Clean up temporary file\n",
    "    os.remove(tmp_path)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Assuming df is your original DataFrame\n",
    "\n",
    "# Function to run lexical parser and get the output vector\n",
    "def run_lexical_parser(file_path):\n",
    "    # Construct the command to run the lexical parser, assuming the script is named LexicalParser.py\n",
    "    # Update the path to LexicalParser.py as needed\n",
    "    command = ['python3', './LexicalParser.py', file_path]\n",
    "    \n",
    "    # Run the command and capture the output\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    \n",
    "    # Extract the output vector from the result, trimming brackets and whitespace\n",
    "    output_vector = result.stdout.strip()[1:-1]  # Remove the leading '[' and trailing ']'\n",
    "    \n",
    "    # Split the string by ',' to get individual numbers as strings\n",
    "    output_vector = output_vector.split(',')\n",
    "    \n",
    "    # Convert the string of numbers into a list of floats, trimming extra whitespace around numbers\n",
    "    features = [float(num.strip()) for num in output_vector]\n",
    "    \n",
    "    # Return the features\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to hold new rows for the enhanced dataset\n",
    "new_rows = []\n",
    "\n",
    "# Iterate over the dataset\n",
    "for index, row in df.iterrows():\n",
    "    code = row['func_code_string']  # Assuming this is the column with code snippets\n",
    "    repo_name = row['repository_name']\n",
    "    \n",
    "    # Save code to a temporary file\n",
    "    with tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.py') as tmp:\n",
    "        tmp.write(code)\n",
    "        tmp_path = tmp.name\n",
    "    \n",
    "    # Run lexical parser and get features\n",
    "    features = run_lexical_parser(tmp_path)\n",
    "    \n",
    "    # Map the features to their respective names (update these names based on your actual features)\n",
    "    features_dict = {\n",
    "        'log_of_numTokens': features[0],\n",
    "        'avg_line_length': features[1],\n",
    "        'stdDev_line_length': features[2],\n",
    "        'log_of_numFunctions': features[3],\n",
    "        'average_params': features[4],\n",
    "        'stdDev_numParams': features[5],\n",
    "        'log_of_python_keywords': features[6],\n",
    "        'log_of_numLiterals': features[7],\n",
    "        'elif': features[8], \n",
    "        'if': features[9],\n",
    "        'else': features[10],\n",
    "        'for': features[11],\n",
    "        'while': features[12],\n",
    "    }\n",
    "    \n",
    "    # Prepare a new row for the enhanced dataset\n",
    "    new_row = {\n",
    "        'repo_name': repo_name,\n",
    "        'code': code,\n",
    "        **features_dict\n",
    "    }\n",
    "    \n",
    "    # Append the new row to the list\n",
    "    new_rows.append(new_row)\n",
    "    \n",
    "    # Clean up the temporary file\n",
    "    os.remove(tmp_path)\n",
    "\n",
    "# Create a new DataFrame with the enhanced dataset\n",
    "enhanced_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Display the first few rows of the enhanced DataFrame\n",
    "print(enhanced_df.head())\n",
    "\n",
    "# Optionally, save the new DataFrame to a CSV file\n",
    "enhanced_df.to_csv('./data/enhanced_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model - Rando Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('./data/enhanced_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(['repo_name', 'code'], axis=1)\n",
    "y = df['repo_name']\n",
    "\n",
    "# Encode the labels (A, B, None) to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "# For LSTM, we need categorical labels\n",
    "y_categorical = to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Random Forest\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "# For LSTM\n",
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X, y_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Random Forest Classifier Report\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming rf_classifier is your trained Random Forest model and X_test is your test dataset\n",
    "\n",
    "# Obtain prediction probabilities for each class\n",
    "probabilities = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "# Calculate the maximum prediction probability for each sample\n",
    "max_probabilities = probabilities.max(axis=1)\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "confidence_percentages = max_probabilities * 100\n",
    "\n",
    "# Optionally, create a DataFrame to display the test samples alongside their prediction confidence\n",
    "test_samples_with_confidence = pd.DataFrame({\n",
    "    'Test Sample Index': X_test.index,\n",
    "    'Prediction Confidence (%)': confidence_percentages\n",
    "})\n",
    "\n",
    "test_samples_with_confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Configure the cross-validation procedure\n",
    "cv = 5  # Number of folds\n",
    "scores = cross_val_score(rf_classifier, X, y_encoded, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print(f'Accuracy scores for {cv}-fold cross-validation:')\n",
    "for i, score in enumerate(scores, 1):\n",
    "    print(f\"Fold {i}: {score:.4f}\")\n",
    "print(f\"Mean accuracy: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting dataset for a single train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_scores = rf_classifier.predict_proba(X_test)[:, 1]  # score for the positive class\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "\n",
    "# Plot the precision-recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, marker='.', label='Random Forest')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rf_classifier.feature_importances_,\n",
    "                                   index = X.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Configure the cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "scores = cross_val_score(rf_classifier, X, y_encoded, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print(f'Accuracy scores for stratified {cv.get_n_splits()}-fold cross-validation:')\n",
    "print(scores)\n",
    "print(f\"Mean accuracy: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the model to disk\n",
    "model_filename = 'test_random_forest_model.joblib'\n",
    "dump(rf_classifier, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the model from disk\n",
    "rf_classifier_loaded = load(\"./models/test_random_forest_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_confidence(model, features):\n",
    "    features = np.array(features).reshape(1, -1)\n",
    "    \n",
    "    # Obtain prediction probabilities and the predicted class\n",
    "    probabilities = model.predict_proba(features)\n",
    "    predicted_class = model.predict(features)[0]  # model.predict returns an array, get the first item\n",
    "    \n",
    "    max_probability = np.max(probabilities)\n",
    "    confidence_percentage = max_probability * 100\n",
    "    \n",
    "    # Print the predicted class along with the confidence of the prediction\n",
    "    print(f\"Predicted class: {predicted_class} with confidence: {confidence_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0 with confidence: 100.00%\n",
      "Predicted class: 1 with confidence: 97.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sina/Library/CloudStorage/OneDrive-UniversityofCalgary/Programming Mac/GitHub/Large_Language_Models_in_RE/primary_experiment/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sina/Library/CloudStorage/OneDrive-UniversityofCalgary/Programming Mac/GitHub/Large_Language_Models_in_RE/primary_experiment/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sina/Library/CloudStorage/OneDrive-UniversityofCalgary/Programming Mac/GitHub/Large_Language_Models_in_RE/primary_experiment/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sina/Library/CloudStorage/OneDrive-UniversityofCalgary/Programming Mac/GitHub/Large_Language_Models_in_RE/primary_experiment/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "example_features_0 = [-1.611416152446210, 38.92307692307690, 18.517836169765000, -6.226536669287470, 2.0, 0.0, -5.53338948872752, -4.1470951276076300, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "example_features_1 = [-2.0555360208262800, 49.6, 27.762905960443400, -6.899723107284870, 2.0, 0.0, -5.5134287461649800, -5.801110818616760, 0.0, -6.899723107284870, -6.899723107284870, 0.0, 0.0]\n",
    "predict_with_confidence(rf_classifier_loaded, example_features_0)\n",
    "predict_with_confidence(rf_classifier_loaded, example_features_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Code 1 - ID 2536\\ndef _get_asset_id_with_enclosure(self, enclosure_id):\\n        \"\"\"Create an Asset with an enclosed foreign object.\\n\\n        This is here to support AssetCompositionSession.set_asset. May need\\n        to add this in other objects to support other osid.Containable objects.\\n        return: (osid.id.Id) - the id of the new Asset\\n\\n        \"\"\"\\n        mgr = self._get_provider_manager(\\'REPOSITORY\\')\\n        query_session = mgr.get_asset_query_session_for_repository(self._catalog_id, proxy=self._proxy)\\n        query_form = query_session.get_asset_query()\\n        query_form.match_enclosed_object_id(enclosure_id)\\n        query_result = query_session.get_assets_by_query(query_form)\\n        if query_result.available() > 0:\\n            asset_id = query_result.next().get_id()\\n        else:\\n            create_form = self.get_asset_form_for_create([ENCLOSURE_RECORD_TYPE])\\n            create_form.set_enclosed_object(enclosure_id)\\n            asset_id = self.create_asset(create_form).get_id()\\n        return asset_id\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Code 0 - ID 1\n",
    "def show_clock_output_clock_time_timezone(self, **kwargs):\n",
    "        \\\"\"\"Auto Generated Code\n",
    "        \\\"\"\"\n",
    "        config = ET.Element(\"config\")\n",
    "        show_clock = ET.Element(\"show_clock\")\n",
    "        config = show_clock\n",
    "        output = ET.SubElement(show_clock, \"output\")\n",
    "        clock_time = ET.SubElement(output, \"clock-time\")\n",
    "        timezone = ET.SubElement(clock_time, \"timezone\")\n",
    "        timezone.text = kwargs.pop('timezone')\n",
    "\n",
    "        callback = kwargs.pop('callback', self._callback)\n",
    "        return callback(config)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\" Code 1 - ID 2536\n",
    "def _get_asset_id_with_enclosure(self, enclosure_id):\n",
    "        \\\"\"\"Create an Asset with an enclosed foreign object.\n",
    "\n",
    "        This is here to support AssetCompositionSession.set_asset. May need\n",
    "        to add this in other objects to support other osid.Containable objects.\n",
    "        return: (osid.id.Id) - the id of the new Asset\n",
    "\n",
    "        \\\"\"\"\n",
    "        mgr = self._get_provider_manager('REPOSITORY')\n",
    "        query_session = mgr.get_asset_query_session_for_repository(self._catalog_id, proxy=self._proxy)\n",
    "        query_form = query_session.get_asset_query()\n",
    "        query_form.match_enclosed_object_id(enclosure_id)\n",
    "        query_result = query_session.get_assets_by_query(query_form)\n",
    "        if query_result.available() > 0:\n",
    "            asset_id = query_result.next().get_id()\n",
    "        else:\n",
    "            create_form = self.get_asset_form_for_create([ENCLOSURE_RECORD_TYPE])\n",
    "            create_form.set_enclosed_object(enclosure_id)\n",
    "            asset_id = self.create_asset(create_form).get_id()\n",
    "        return asset_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0 with confidence: 95.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sina/Library/CloudStorage/OneDrive-UniversityofCalgary/Programming Mac/GitHub/Large_Language_Models_in_RE/primary_experiment/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sina/Library/CloudStorage/OneDrive-UniversityofCalgary/Programming Mac/GitHub/Large_Language_Models_in_RE/primary_experiment/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Testing changing the code style\n",
    "\"\"\"\n",
    "prompt: change this code somehow, keep the exact functionality, but not recognizable as it is on a code stylometry analysis. change its style:\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"  \n",
    "def config_and_invoke_callback(self, **params):\n",
    "    \\\"\"\" Changed code - Repo 0 - ID 1\n",
    "    Refactored Configuration Setup\n",
    "    \\\"\"\"\n",
    "    root_config = ET.Element(\"configuration\")\n",
    "    clock_display = ET.Element(\"clockDisplay\")\n",
    "    root_config.append(clock_display)\n",
    "    clock_output = ET.SubElement(clock_display, \"outputSection\")\n",
    "    time_display = ET.SubElement(clock_output, \"timeDisplay\")\n",
    "    local_timezone = ET.SubElement(time_display, \"localTimezone\")\n",
    "    local_timezone.text = params.get('timezone')\n",
    "\n",
    "    # Remove 'timezone' to avoid passing it further accidentally\n",
    "    params.pop('timezone', None)\n",
    "    # Get the callback function, default to internal if not provided\n",
    "    invoke_callback = params.get('callback', self.default_callback)\n",
    "    # Remove 'callback' to clean up params\n",
    "    params.pop('callback', None)\n",
    "\n",
    "    return invoke_callback(root_config)\n",
    "\"\"\"\n",
    "changed_code_0 = [-1.8310298730568912, 40.25, 22.313260159541198, -6.690842277418564, 2.0, 0.0, -5.592229988750454, -4.388257184424518, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "predict_with_confidence(rf_classifier_loaded, changed_code_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1 with confidence: 97.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sina/Library/CloudStorage/OneDrive-UniversityofCalgary/Programming Mac/GitHub/Large_Language_Models_in_RE/primary_experiment/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sina/Library/CloudStorage/OneDrive-UniversityofCalgary/Programming Mac/GitHub/Large_Language_Models_in_RE/primary_experiment/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def fetch_asset_identifier_by_enclosure(self, enclosure_identifier):\n",
    "    \\\"\"\" Changed code - Repo 1 - ID 2536\n",
    "    Generates an asset ID for a given enclosure ID.\n",
    "\n",
    "    Useful in scenarios where asset compositions need to be managed or adjusted.\n",
    "    Ensures compatibility with various osid.Containable objects as required.\n",
    "    \n",
    "    :return: The unique identifier of the newly associated or created asset.\n",
    "    \\\"\"\"\n",
    "    repository_manager = self.obtain_repository_manager('REPOSITORY')\n",
    "    asset_query_session = repository_manager.obtain_asset_query_session_for_repository(self.catalogue_id, proxy=self.proxy_setting)\n",
    "    asset_search_criteria = asset_query_session.construct_asset_query()\n",
    "    asset_search_criteria.constrain_by_enclosure(enclosure_identifier)\n",
    "    found_assets = asset_query_session.query_assets_using_criteria(asset_search_criteria)\n",
    "    \n",
    "    if found_assets.has_next():\n",
    "        new_asset_id = found_assets.next_item().identify()\n",
    "    else:\n",
    "        asset_creation_form = self.initiate_asset_creation([ENCLOSURE_RECORD_TYPE])\n",
    "        asset_creation_form.define_enclosure(enclosure_identifier)\n",
    "        new_asset_id = self.commit_new_asset(asset_creation_form).identify()\n",
    "    return new_asset_id\n",
    "\"\"\"\n",
    "\n",
    "changed_code_1_1 = [-2.2378349092458842, 53.68181818181818, 34.58651865578947, -7.074116816197362, 2.0, 0.0, -5.687822455077471, -6.380969635637417, 0.0, -7.074116816197362, -7.074116816197362, 0.0, 0.0]\n",
    "predict_with_confidence(rf_classifier_loaded, changed_code_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1 with confidence: 86.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sina/Library/CloudStorage/OneDrive-UniversityofCalgary/Programming Mac/GitHub/Large_Language_Models_in_RE/primary_experiment/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sina/Library/CloudStorage/OneDrive-UniversityofCalgary/Programming Mac/GitHub/Large_Language_Models_in_RE/primary_experiment/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "def retrieve_asset_id(self, enclosure_key):\n",
    "    \\\"\"\" Changed code - Repo 1 - ID 2536\n",
    "    Retrieves or creates an asset linked to a specific enclosure, ensuring\n",
    "    compatibility and manageability within asset compositions.\n",
    "\n",
    "    :param enclosure_key: Unique identifier for the enclosure.\n",
    "    :return: Identifier of the associated or newly created asset.\n",
    "    \\\"\"\"\n",
    "    asset_id = self._search_existing_asset(enclosure_key)\n",
    "    if not asset_id:\n",
    "        asset_id = self._create_and_fetch_asset_id(enclosure_key)\n",
    "    return asset_id\n",
    "\n",
    "def _search_existing_asset(self, enclosure_key):\n",
    "    repository_service = self._fetch_repository_service('REPOSITORY')\n",
    "    asset_finder = repository_service.start_asset_search(self.catalog_id, self.proxy)\n",
    "    asset_finder.set_enclosure_criteria(enclosure_key)\n",
    "    found_assets = asset_finder.execute_search()\n",
    "    \n",
    "    return found_assets.first().id if found_assets.count() > 0 else None\n",
    "\n",
    "def _create_and_fetch_asset_id(self, enclosure_key):\n",
    "    asset_builder = self._initiate_asset_creation_process([ENCLOSURE_RECORD_TYPE])\n",
    "    asset_builder.assign_enclosure(enclosure_key)\n",
    "    return self._finalize_asset_creation(asset_builder).id\n",
    "\n",
    "def _fetch_repository_service(self, service_name):\n",
    "    return self._access_provider_manager(service_name)\n",
    "\n",
    "def _initiate_asset_creation_process(self, record_types):\n",
    "    creation_interface = self.prepare_asset_creation_interface(record_types)\n",
    "    return creation_interface\n",
    "\n",
    "def _finalize_asset_creation(self, builder):\n",
    "    return builder.complete_creation()\n",
    "\"\"\"\n",
    "\n",
    "changed_code_1_2 = [-1.9040404277304552, 41.42857142857143, 27.68763337695742, -5.487559366186565, 2.0, 0.0, -5.487559366186565, -6.18070654674651, 0.0, -6.586171654854675, -7.27931883541462, 0.0, 0.0]\n",
    "predict_with_confidence(rf_classifier_loaded, changed_code_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1 with confidence: 59.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sina/Library/CloudStorage/OneDrive-UniversityofCalgary/Programming Mac/GitHub/Large_Language_Models_in_RE/primary_experiment/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sina/Library/CloudStorage/OneDrive-UniversityofCalgary/Programming Mac/GitHub/Large_Language_Models_in_RE/primary_experiment/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Changed code - Repo 1 - ID 2536\n",
    "class AssetManager:\n",
    "    def __init__(self, repository_identifier, proxy):\n",
    "        self.repository_identifier = repository_identifier\n",
    "        self.proxy = proxy\n",
    "\n",
    "    def _obtain_repository_manager(self, service_type='REPOSITORY'):\n",
    "        # Simulates fetching a service manager for repositories; abstracted for clarity.\n",
    "        return MockRepositoryManager(service_type)\n",
    "\n",
    "    def _query_for_asset(self, enclosure_id):\n",
    "        with self._repository_session_context(self.repository_identifier, self.proxy) as session:\n",
    "            asset_query = session.formulate_asset_query()\n",
    "            asset_query.filter_by_enclosure(enclosure_id)\n",
    "            return session.query_assets(asset_query)\n",
    "\n",
    "    def _repository_session_context(self, repository_id, proxy):\n",
    "        # Context manager to encapsulate session management for querying or creating assets.\n",
    "        manager = self._obtain_repository_manager()\n",
    "        return manager.session_for_repository(repository_id, proxy)\n",
    "\n",
    "    def _create_asset_if_missing(self, enclosure_id, assets):\n",
    "        if assets:\n",
    "            return assets[0].id  # Assuming assets is a list-like object with asset objects.\n",
    "        else:\n",
    "            with self._repository_session_context(self.repository_identifier, self.proxy) as session:\n",
    "                asset_creation_form = session.asset_creation_template([ENCLOSURE_RECORD_TYPE])\n",
    "                asset_creation_form.enclosure = enclosure_id\n",
    "                new_asset = session.create_asset(asset_creation_form)\n",
    "                return new_asset.id\n",
    "\n",
    "    def get_or_create_asset_id_by_enclosure(self, enclosure_id):\n",
    "        existing_assets = self._query_for_asset(enclosure_id)\n",
    "        return self._create_asset_if_missing(enclosure_id, existing_assets)\n",
    "\n",
    "# Mock classes to simulate behavior of repository manager and session, for illustrative purposes.\n",
    "class MockRepositoryManager:\n",
    "    def __init__(self, service_type):\n",
    "        self.service_type = service_type\n",
    "\n",
    "    def session_for_repository(self, repository_id, proxy):\n",
    "        return MockSession(repository_id, proxy)\n",
    "\n",
    "class MockSession:\n",
    "    def __init__(self, repository_id, proxy):\n",
    "        self.repository_id = repository_id\n",
    "        self.proxy = proxy\n",
    "\n",
    "    def __enter__(self):\n",
    "        # Initialize session resources\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        # Clean up session resources\n",
    "        pass\n",
    "\n",
    "    def formulate_asset_query(self):\n",
    "        # Returns a mock query object\n",
    "        return MockQuery()\n",
    "\n",
    "    def query_assets(self, query):\n",
    "        # Simulate asset querying\n",
    "        return []\n",
    "\n",
    "    def asset_creation_template(self, record_types):\n",
    "        # Returns a form for asset creation\n",
    "        return MockCreationForm()\n",
    "\n",
    "    def create_asset(self, creation_form):\n",
    "        # Simulate asset creation\n",
    "        return MockAsset()\n",
    "\n",
    "class MockQuery:\n",
    "    def filter_by_enclosure(self, enclosure_id):\n",
    "        pass\n",
    "\n",
    "class MockCreationForm:\n",
    "    def __init__(self):\n",
    "        self.enclosure = None\n",
    "\n",
    "class MockAsset:\n",
    "    @property\n",
    "    def id(self):\n",
    "        return 'mock_asset_id'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "changed_code_1_3 = [-1.7534533703673156, 35.05952380952381, 28.02251727574284, -5.0974923381895225, 2.1666666666666665, 0.8574929257125442, -5.790639518749468, -6.889251807417577, 0.0, -7.987864096085687, -7.987864096085687, 0.0, 0.0]\n",
    "predict_with_confidence(rf_classifier_loaded, changed_code_1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming X is already normalized if necessary\n",
    "# Reshape input to be 3D [samples, timesteps, features] for LSTM\n",
    "X_train_lstm_reshaped = np.reshape(X_train_lstm.values, (X_train_lstm.shape[0], 1, X_train_lstm.shape[1]))\n",
    "X_test_lstm_reshaped = np.reshape(X_test_lstm.values, (X_test_lstm.shape[0], 1, X_test_lstm.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train_lstm_reshaped.shape[1], X_train_lstm_reshaped.shape[2])))\n",
    "model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train_lstm_reshaped, y_train_lstm, epochs=10, batch_size=32, validation_data=(X_test_lstm_reshaped, y_test_lstm), verbose=2)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_lstm = model.predict(X_test_lstm_reshaped)\n",
    "y_pred_lstm_classes = np.argmax(y_pred_lstm, axis=1)\n",
    "y_test_classes = np.argmax(y_test_lstm, axis=1)\n",
    "\n",
    "print(\"\\nLSTM Classifier Report\")\n",
    "print(classification_report(y_test_classes, y_pred_lstm_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
